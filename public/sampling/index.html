<!doctype html><html lang="en-US"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Sampling Error Calculator (for Tracing data)</title><script defer="defer" src="js/chunk-vendors.b581fe6e.js"></script><script defer="defer" src="js/app.46f36614.js"></script></head><body><header><a href="/">HeinrichHartmann.com</a></header><main class="markdown-container"><article class="markdown-body"><noscript><strong>We're sorry but sampling doesn't work properly without JavaScript enabled. Please enable it to continue.</strong></noscript><div id="app"></div><h1 id="explanation">Explanation</h1><p>We model the error introduce by <a href="https://en.wikipedia.org/wiki/Bernoulli_sampling">Bernuoulli sampling</a> to a number of statistics that are relevant for IT operations. This sampling model used by OpenTelemetry to sample on trace-level (although the <a href="https://github.com/open-telemetry/oteps/blob/main/text/trace/0170-sampling-probability.md#traceidratio-sampler">spec</a> is not clear on this.)</p><p>For each point in the population we make independent sampling decisions with probability given by the sampling rate.</p><ul><li>With sampling rate 100% all the elements in the population are retained.</li><li>With sampling rate 50%, there is a 50% chance that any given point will be retained.</li><li>With sampling rate 0% the sample is empty.</li></ul><p>In the following we denote by $N$ the number of requests in the population, by $K$ the number of errors, and by $n$ the size of the sample.</p><h2 id="estimation">Estimation</h2><p>For some statistics, we have theoretical models that allow us to estimate the expected values and variances.</p><p>In the Bernoulli model, the sample size $n$ follows a <a href="https://en.wikipedia.org/wiki/Binomial_distribution#Statistical_inference">Binomial distribution</a>, $n \sim B(N,p)$.s where with $p$ is the sampling rate $p$, and $N = \#X$ is population size. Hence the expected sample size is $E[n] = N \cdot p$, and $Var[n] = N \cdot p \cdot (1-p)$. These formulas are used to calculate the <em>Request Count</em> and <em>Request Rate</em> statistics.</p><p>For the error rate calculation, we denote by $k \leq n$ the number of errors in the sample set. The error count also follows a binomial distribution $k \sim B(K,p)$.</p><p>The rate of errors in the sample is denoted by $r = k/n$ (for $n&gt;0$). Using the observation $k$ conditioned on $n=const$ follows a <a href="https://en.wikipedia.org/wiki/Hypergeometric_distribution">Hypergeometric distribution</a> $Hyp(N,K,n)$, and filling in $r = K/N$ for $n=0$, one derives the formula $E[r] = K/N$, and</p><p>$$ Var[r] = \frac{K (N-K)}{N^2} \frac{1}{N-1} \sum_{n=1}^N { N \choose n } p^n (1-p)^{N-n} \frac{N-n}{n} $$</p><p>We use these formula for estimating the standard-deviation of the <em>Error Rate</em> above.</p><details>This can be seen as follows:<p>$$ \begin{aligned} E[r] &amp;= \sum_{S \subset [N]} P\{S\} \cdot r(S) \\ &amp;= \sum_{S \subset [N]} p^{\# S}(1-p)^{N - \#S} \cdot r(S) \\ &amp;= \frac{K}{N} q^N + \sum_{n \geq 1,k \leq n} p^n q^m \cdot \frac{k}{n} \cdot \# \{ S \subset [N] | \#S=n, \#S\cap[K] = k \} \\ &amp;= \frac{K}{N} q^N + \sum_{n \geq 1,k \leq n} { N \choose n } p^n q^m \frac{ { K \choose k } { N-K \choose n-k } }{ { N \choose n } } \cdot \frac{k}{n} \\ &amp;= \frac{K}{N} q^N + \sum_{n \geq 1} B(N,p)[n] \cdot \frac{1}{n} \cdot \sum_{k \leq n} Hyp(N,K,n)[k] \cdot k \\ &amp;= \frac{K}{N} q^N + \sum_{n \geq 1} B(N,p)[n] \cdot \frac{1}{n} \cdot \frac{n K}{N} \\ &amp;= \frac{K}{N} q^N + \frac{K}{N} (1 - q^N) \\ &amp;= \frac{K}{N} \\ E[r^2] &amp;= \frac{K^2}{N^2} q^N + \sum_{n \geq 1} B(N,p)[n] \cdot \sum_{k \leq n} Hyp(N,K,n)[k] \cdot \frac{k^2}{n^2} \\ &amp;= \frac{K^2}{N^2} q^N + \sum_{n \geq 1} B(N,p)[n] \cdot \frac{1}{n^2} \cdot [ n \frac{K (N-K) (N-n)}{N^2(N-1)} + n^2 \frac{K^2}{N^2} ] \\ &amp;= \frac{K^2}{N^2} q^N + \sum_{n \geq 1} B(N,p)[n] \cdot \frac{K^2}{N^2} [ \frac{1}{n} \frac{L m}{K(N-1)} + 1] \\ &amp;= \frac{K^2}{N^2} q^N + \frac{K^2}{N^2} \cdot (1-q^m) + \frac{L}{K(N-1)} \cdot [ \sum_{n \geq 1} B(N,p)[n] \cdot \frac{m}{n} ] \\ &amp;= \frac{K^2}{N^2} + \frac{K L}{N^2(N-1)} \cdot [ \sum_{n \geq 1} B(N,p)[n] \cdot \frac{m}{n} ] \\ Var[r] &amp;= E[r^2] - E[r]^2 \\ &amp;= \frac{K L}{N^2(N-1)} \cdot \sum_{n \geq 1} B(N,p)[n] \cdot \frac{m}{n} \end{aligned} $$</p><p>Where $q = 1-p, m = N-n,L=N-K$, and we used the known formulas for moments of the Hypergeometric Distribution.</p></details><h2 id="simulation">Simulation</h2><p>We simulate multiple iterations of sampling decisions is straight forward. We repeatedly select a subset $S \subset X$ by running Bernoulli experiments for each sample $x \in X$. Then we compute the estimator on the sample $S$, and record the results. In the above tables we report mean, and standard-deviation of the computed estimations.</p><p>Note that mean and standard-deviation are sensible measure here, since the distribution of the estimators across different samples is well behaved (very close to normal), in all cases.</p><h2 id="comments">Comments</h2><script src="https://utteranc.es/client.js" repo="HeinrichHartmann/comments" issue-term="title" label="Comment" theme="github-light" crossorigin="anonymous" async></script></article></main><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css" integrity="sha384-ZPe7yZ91iWxYumsBEOn7ieg8q/o+qh/hQpSaPow8T6BwALcXSCS6C6fSRPIAnTQs" crossorigin="anonymous"><script defer="defer" src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js" integrity="sha384-ljao5I1l+8KYFXG7LNEA7DyaFvuvSCmedUf6Y6JI7LJqiu8q5dEivP2nDdFH31V4" crossorigin="anonymous"></script><script defer="defer" src="https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"></script><script>document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          // customised options
          // • auto-render specific keys, e.g.:
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          // • rendering keys, e.g.:
          throwOnError : false
        });
    });</script><script src="https://d3js.org/d3.v6.js"></script></body></html>